# -*- coding: utf-8 -*-
"""MachineLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CWhECa6ZkAfCIqdnwUhkhvjhNeONW3UT

#**M√©todos** **Ensemble**

###1Ô∏è‚É£ Introdu√ß√£o ao Problema

Objetivo: Prever a cor do vinho (tinto ou branco) com base em suas caracter√≠sticas qu√≠micas.

- Modelos utilizados:
  - Random Forest (RF) ‚Üí Conjunto de √°rvores de decis√£o independentes.

  - Gradient Boosting (GB) ‚Üí Modelos sequenciais corrigindo erros anteriores.
- Motiva√ß√£o: Comparar os dois modelos e entender suas diferen√ßas.

## üìå O que s√£o M√©todos Ensemble?
M√©todos ensemble s√£o t√©cnicas que combinam m√∫ltiplos modelos de aprendizado de m√°quina para obter previs√µes mais precisas e robustas.
A ideia principal √© que v√°rios modelos juntos capturam padr√µes melhor do que um √∫nico modelo isolado.

### üîπ Tipos de M√©todos Ensemble:
1Ô∏è‚É£ **Bagging (Bootstrap Aggregating)** ‚Üí Treina v√°rios modelos independentes e combina suas previs√µes. Exemplo: **Random Forest**.

2Ô∏è‚É£ **Boosting** ‚Üí Treina modelos sequencialmente, onde cada novo modelo corrige os erros do anterior. Exemplo: **Gradient Boosting**.

3Ô∏è‚É£ **Stacking (Stacked Generalization)** ‚Üí Combina m√∫ltiplos modelos diferentes e usa um modelo final para tomar a decis√£o.

### üîπ Benef√≠cios dos M√©todos Ensemble:
‚úî **Maior precis√£o**: Reduz o erro do modelo.

‚úî **Menos overfitting**: Modelos como Random Forest ajudam a evitar overffiting.

‚úî **Melhor desempenho**: Modelos combinados aproveitam diferentes padr√µes nos dados.


Nesta an√°lise, comparo dois dos principais m√©todos ensemble: **Random Forest (Bagging)** e **Gradient Boosting (Boosting)**, aplicados na previs√£o da cor do vinho.

##Imports
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn import metrics
from sklearn.model_selection import cross_val_score

"""## Carregar e explorar o dataset

"""

url = '/content/winequality-merged.csv'
arquivo = pd.read_csv(url)
arquivo.head()

print("\nüìå Informa√ß√µes gerais sobre o dataset:")
print(arquivo.info())

print("\nüìå Estat√≠sticas descritivas das vari√°veis num√©ricas:")
print(arquivo.describe())

print("\nüìå Contagem de cada classe da vari√°vel alvo 'color':")
print(arquivo['color'].value_counts())

"""## Pr√©-processamento dos dados


"""

# Converter a vari√°vel alvo (cor) para valores num√©ricos
arquivo['color'] = arquivo['color'].map({'red': 0, 'white': 1})
# Verificar se h√° colunas n√£o num√©ricas
arquivo = arquivo.select_dtypes(include=['number'])

"""## Visualiza√ß√£o dos dados

"""

# Histogramas para entender a distribui√ß√£o das vari√°veis
arquivo.hist(figsize=(20, 15), bins=20)
plt.show()

# Boxplots para identificar outliers
arquivo.boxplot(figsize=(20, 10), rot=90)
plt.show()

# Mapa de calor para analisar a correla√ß√£o entre vari√°veis
plt.figure(figsize=(12, 8))
sns.heatmap(arquivo.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title("Mapa de Calor da Correla√ß√£o entre as Vari√°veis")
plt.show()

"""## Prepara√ß√£o para Treinamento

"""

# Definir vari√°veis independentes (X) e dependente (y)
y = arquivo['color']
X = arquivo.drop(['color', 'quality'], axis=1)

# Divis√£o dos dados em treino e teste
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""## Treinamento e Avalia√ß√£o dos Modelos Ensemble"""

rf_model = RandomForestClassifier(
    n_estimators=20,
    max_depth=4,
    min_samples_split=20,
    min_samples_leaf=8,
    max_features='sqrt',
    random_state=42)

"""###2Ô∏è‚É£ Explica√ß√£o dos Modelos

####üìç Random Forest
- Constr√≥i v√°rias √°rvores de decis√£o independentes.
- Cada √°rvore recebe um subconjunto aleat√≥rio dos dados.
- O resultado final √© a m√©dia das previs√µes de todas as √°rvores (voto majorit√°rio para classifica√ß√£o).

‚úî Vantagens:

‚úÖ R√°pido para treinar.

‚úÖ Menos propenso a overfitting (por causa do bagging).

‚úÖ Bom para datasets m√©dios/grandes.

‚ùå Limita√ß√µes:

üö´ Pode ser menos preciso do que m√©todos boosteados.

üö´ Ocupa mais mem√≥ria, pois cria muitas √°rvores.


"""

gb_model = GradientBoostingClassifier(
    n_estimators=150,
    learning_rate=0.01,
    max_depth=2,
    subsample=0.6,
    random_state=42
)

"""####üìç Gradient Boosting

- Constr√≥i √°rvores sequencialmente, onde cada nova √°rvore corrige os erros da anterior.
- Aprendizado mais lento, por√©m mais preciso.
- Usa um fator de aprendizado (learning_rate) para ajustar o peso das novas √°rvores.

‚úî Vantagens:

‚úÖ Melhor desempenho em datasets menores.

‚úÖ Identifica padr√µes mais complexos.

‚ùå Limita√ß√µes:

üö´ Mais propenso a overfitting.

üö´ Requer ajuste fino de hiperpar√¢metros.

üö´ Treinamento mais demorado.


"""

# Treinando os modelos
rf_model.fit(x_train, y_train)
gb_model.fit(x_train, y_train)



"""## Compara√ß√£o dos Modelos

üìç An√°lise de Performance

- Acur√°cia de Treinamento vs. Teste ‚Üí Para verificar overfitting.
- Matriz de Confus√£o ‚Üí Para entender erros e acertos.
- An√°lise das Previs√µes ‚Üí Compara√ß√£o de erros exclusivos.
"""

models = {"Random Forest": rf_model, "Gradient Boosting": gb_model}

for name, model in models.items():
    print(f"\nüîç Avalia√ß√£o do modelo: {name}")

    # Acur√°cia no conjunto de treinamento
    train_accuracy = model.score(x_train, y_train)
    print(f'Acur√°cia no Treino: {train_accuracy:.4f}')

    # Acur√°cia no conjunto de teste
    y_pred = model.predict(x_test)
    test_accuracy = accuracy_score(y_test, y_pred)
    print(f'Acur√°cia no Teste: {test_accuracy:.4f}')

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f'Precis√£o: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1-score: {f1:.4f}')

# Valida√ß√£o Cruzada para melhor avalia√ß√£o dos modelos
cv_folds = 5

rf_scores = cross_val_score(rf_model, X, y, cv=cv_folds, scoring='accuracy')
gb_scores = cross_val_score(gb_model, X, y, cv=cv_folds, scoring='accuracy')

print(f"üìä Valida√ß√£o Cruzada - Random Forest (m√©dia de {cv_folds} folds): {rf_scores.mean():.4f}")
print(f"üìä Valida√ß√£o Cruzada - Gradient Boosting (m√©dia de {cv_folds} folds): {gb_scores.mean():.4f}")

for name, model in models.items():
    # Fazer previs√µes para o modelo atual
    y_pred = model.predict(x_test)

    conf_matrix = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(6, 5))
    sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', linewidths=0.5)
    plt.xlabel("Predito")
    plt.ylabel("Real")
    plt.title(f"Matriz de Confus√£o - {name}")
    plt.show()

for name, model in models.items():
    # Fazer previs√µes no conjunto de teste
    y_pred = model.predict(x_test)

    # Calcular a matriz de confus√£o espec√≠fica para o modelo atual
    cm = confusion_matrix(y_test, y_pred)

    # Normalizar a matriz de confus√£o
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    # Exibir os valores normalizados
    print(f"\nüìä Matriz de Confus√£o Normalizada - {name}")
    print("True Positive (rate): ", cm[1, 1], "({0:0.4f})".format(cm_norm[1, 1]))
    print("True Negative (rate): ", cm[0, 0], "({0:0.4f})".format(cm_norm[0, 0]))
    print("False Positive (rate):", cm[1, 0], "({0:0.4f})".format(cm_norm[1, 0]))
    print("False Negative (rate):", cm[0, 1], "({0:0.4f})".format(cm_norm[0, 1]))

# Fazer previs√µes
y_pred_rf = rf_model.predict(x_test)
y_pred_gb = gb_model.predict(x_test)

# Comparar previs√µes entre os modelos
iguais = sum(y_pred_rf == y_pred_gb)
total = len(y_pred_rf)

print(f"N√∫mero de previs√µes id√™nticas entre os modelos: {iguais}/{total} ({(iguais/total)*100:.2f}%)")

for name, model in models.items():
   # Curva ROC
    y_probs = model.predict_proba(x_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_probs)
    roc_auc = auc(fpr, tpr)
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'Curva ROC - {name}')
    plt.legend(loc="lower right")
    plt.show()

"""
## Um pouco mais detalhado...
"""

y_pred_rf = rf_model.predict(x_test)
y_pred_gb = gb_model.predict(x_test)

# Compara√ß√£o dos vetores de previs√£o
print("Os modelos fizeram as mesmas previs√µes?", np.array_equal(y_pred_rf, y_pred_gb))

# Compara√ß√£o entre as previs√µes dos dois modelos
diffs = np.sum(y_pred_rf != y_pred_gb)
print(f"N√∫mero de previs√µes diferentes entre os modelos: {diffs}")

# √çndices das previs√µes erradas por cada modelo
erros_rf = np.where(y_pred_rf != y_test)[0]
erros_gb = np.where(y_pred_gb != y_test)[0]

# Comparar erros √∫nicos entre os modelos
erros_unicos_rf = set(erros_rf) - set(erros_gb)
erros_unicos_gb = set(erros_gb) - set(erros_rf)

print(f"N√∫mero de erros exclusivos do Random Forest: {len(erros_unicos_rf)}")
print(f"N√∫mero de erros exclusivos do Gradient Boosting: {len(erros_unicos_gb)}")

"""## Import√¢ncia das Features

4Ô∏è‚É£ Import√¢ncia das Features
- Analise de quais vari√°veis tiveram maior impacto nas previs√µes.
- Random Forest e Gradient Boosting podem atribuir pesos diferentes √†s features.
- Isso pode indicar quais atributos qu√≠micos do vinho s√£o mais relevantes para definir sua cor.
"""

importances_rf = rf_model.feature_importances_
importances_gb = gb_model.feature_importances_

print("\nüìå Import√¢ncia das Features - Random Forest:")
for feature, importance in zip(X.columns, importances_rf):
    print(f"{feature}: {importance:.4f}")

print("\nüìå Import√¢ncia das Features - Gradient Boosting:")
for feature, importance in zip(X.columns, importances_gb):
    print(f"{feature}: {importance:.4f}")

"""## üç∑ Aplica√ß√µes Pr√°ticas dos M√©todos Ensemble

Os m√©todos ensemble s√£o amplamente utilizados em diversos setores para resolver problemas complexos de classifica√ß√£o e regress√£o. Algumas aplica√ß√µes incluem:

‚úî **Medicina e Diagn√≥stico M√©dico** üè•
   - Detec√ß√£o de doen√ßas a partir de exames de imagem (c√¢ncer, pneumonia, retinopatia diab√©tica).
   - An√°lise de exames laboratoriais para prever condi√ß√µes m√©dicas.

‚úî **Finan√ßas e Detec√ß√£o de Fraudes üí≥**
   - Detec√ß√£o de transa√ß√µes fraudulentas com Random Forest e Gradient Boosting.
   - Previs√£o de inadimpl√™ncia e an√°lise de cr√©dito.

‚úî **Reconhecimento de Padr√µes e Processamento de Imagem üì∑**
   - Reconhecimento facial e biometria.
   - Detec√ß√£o de objetos e segmenta√ß√£o de imagens.

‚úî **Previs√£o de Demanda e Otimiza√ß√£o Log√≠stica üöõ**
   - Previs√£o de vendas com base em s√©ries temporais.
   - Otimiza√ß√£o de rotas e estoques utilizando modelos de aprendizado ensemble.

‚úî **Classifica√ß√£o de Texto e An√°lise de Sentimentos üìÑ**
   - Detec√ß√£o de spam em e-mails e mensagens.
   - An√°lise de sentimentos em redes sociais e avalia√ß√µes de produtos.

‚úî **Sistemas de Recomenda√ß√£o üéµüé•**
   - Recomenda√ß√£o de m√∫sicas, filmes e produtos personalizados.
   - Modelos ensemble combinam diferentes algoritmos para melhorar sugest√µes.

Os m√©todos ensemble s√£o extremamente vers√°teis e s√£o aplicados sempre que h√° necessidade de alta precis√£o e robustez no aprendizado de m√°quina.

##üìå Conclus√£o

‚úÖ O Random Forest tive um desempenho melhor em termos de acertos e erros.

‚úÖ O Gradient Boosting errou em mais pontos exclusivos, enquanto o Random Forest foi mais est√°vel.

‚úÖ Ambos os modelos podem ser usados para prever a cor do vinho com alta confiabilidade.
"""